#!/usr/bin/env ruby
# The MIT License (MIT)
# Copyright (c) 2016 Christian Parpart (DaWanda GmbH) <christian@dawanda.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

require 'rubygems'
require 'em-eventsource'
require 'net/http'
require 'fileutils'
require 'logger'
require 'json'

# {{{ app instance health check
class HealthCheck
  def initialize
    @mode = :http # :http, :tcp, :redis_master, :redis_slave
    @http_uri = "/"
    @http_ignore_1xx = true
    @tcp_send = ""
    @tcp_expect = ""
  end
end
# }}}
class AppInstance # {{{
  attr_accessor :name, :host, :port

  def initialize(name, host, port)
    @name = name
    @host = host
    @port = port
  end
end
# }}}
class AppCluster # {{{
  attr_accessor :instances, :app_id, :service_port, :mode

  def initialize(app_id, service_port, mode)
    @instances = []
    @app_id = app_id
    @service_port = service_port
    @mode = mode
  end

  def add_backend(name, host, port)
    @instances << AppInstance.new(name, host, port)
  end
end
# }}}
class HaproxyBuilder # {{{
  attr_accessor :binpath, :cfgfile, :pidfile, :bindaddr, :logger

  def initialize(binpath, cfgfile, pidfile, bindaddr, port, logger)
    @binpath = binpath
    @cfgfile = cfgfile
    @pidfile = pidfile
    @bindaddr = bindaddr
    @port = port
    @logger = logger
  end

  def apply(clusters, force)
    tmpfile = "#{@cfgfile}.tmp"
    write_config(tmpfile, clusters)
    if !File.exist?(@cfgfile) then
      logger.debug "File new. #{@cfgfile} reloaded."
      FileUtils.mv(tmpfile, @cfgfile)
      ensure_haproxy
    elsif !FileUtils.identical?(tmpfile, @cfgfile) then
      logger.debug "File changed. #{@cfgfile} reloaded."
      FileUtils.rm(@cfgfile)
      FileUtils.mv(tmpfile, @cfgfile)
      ensure_haproxy
    else
      logger.debug "Nothing changed. #{@cfgfile} not reloaded."
      FileUtils.rm(tmpfile)
      ensure_haproxy if force
    end
  end

  def valid_pid?(pid)
    Process.kill(0, pid)
    # pid = Process.spawn(status_cmd)
    # Process.wait(pid)
    # pid, status = Process.waitpid2(pid)
    # status.exitstatus == 0
  rescue => bang
    logger.debug "Error while testing for valid PID #{pid}. #{bang}"
    false
  end

  def kill_process(pid)
    Process.kill(:SIGKILL, pid)
  rescue => bang
    logger.debug "Error while killing PID #{pid}. #{bang}"
  end

  def start_haproxy
    args = [@binpath, '-f', @cfgfile, '-p', @pidfile, '-D', '-q']
    logger.info "Starting haproxy. #{args.join(' ')}"
    io = IO.popen(args.join(' '))
    output = io.read
    io.close
    logger.debug "start haproxy program output: #{output}"
  end

  def reload_haproxy(pid)
    args = [@binpath, '-D', '-p', @pidfile, '-f', @cfgfile, '-sf', pid]
    logger.info "Reloading haproxy. #{args.join(' ')}"
    io = IO.popen(args.join(' '))
    output = io.read
    io.close
    logger.debug "reload haproxy program output: #{output}"
  end

  def ensure_haproxy
    if File.exist?(@pidfile) then
      pid = File.read(@pidfile).strip.to_i
      if valid_pid?(pid) then
        reload_haproxy(pid)
      else
        logger.info "PID file #{@pidfile} contains an invalid PID #{pid}."
        kill_process(pid)
        start_haproxy
      end
    else
      start_haproxy
    end
  end

  def write_config(filename, clusters)
    logger.debug "HaproxyBuilder.write_config(\"#{filename}\")"
    file = File.open(filename, File::CREAT | File::TRUNC | File::WRONLY, 0644)

    file.write "global\n"
    file.write "  maxconn 32768\n"
    file.write "\n"

    file.write "defaults\n"
    file.write "  timeout client 90000\n"
    file.write "  timeout server 90000\n"
    file.write "  timeout connect 90000\n"
    file.write "  timeout queue 90000\n"
    file.write "  timeout http-request 90000\n"
    file.write "\n"

    if @port != 0 then
      file.write "listen haproxy\n"
      file.write "  bind #{@bindaddr}:#{@port}\n"
      file.write "  mode http\n"
      file.write "  stats enable\n"
      file.write "  stats uri /\n"
      file.write "  stats admin if TRUE\n"
      file.write "  monitor-uri /haproxy?monitor\n"
      file.write "\n"
    end

    clusters.each do |app_id, cluster|
      # kill the first / and replace any other occurence with a dot
      app_id = app_id.slice(1, app_id.length - 1)
      app_id = app_id.gsub('/', '.')

      file.write "listen #{app_id}\n"
      file.write "  bind #{@bindaddr}:#{cluster.service_port}\n"
      file.write "  balance leastconn\n"

      healthcheck_http_uri = '/'    # TODO: load from marathon
      healthcheck_interval = 10000  # TODO: load from marathon

      if cluster.mode == 'http' then
        file.write "  mode http\n"
        file.write "  option forwardfor\n"
        file.write "  option abortonclose\n"
      else
        file.write "  mode tcp\n"
      end
      # TODO support custom haproxy option fields

      cluster.instances.each do |i|
        name = i.host.gsub(`domainname`.strip, '').gsub(/\.$/, '') + ":" + i.port.to_s
        file.write "  server #{name} #{i.host}:#{i.port}" +
                   " check inter #{healthcheck_interval}" +
                   "\n"
      end
      file.write "\n"
    end
    file.close
  end
end
# }}}
class UpstreamConfDirHandler # {{{
  attr_accessor :confd_path, :logger

  def initialize(confd_path, logger)
    @confd_path = confd_path
    @logger = logger

    FileUtils.mkdir_p(@confd_path)
  end

  def apply(clusters, force)
    old_files = collect_files
    new_files = []

    clusters.each do |app_id, cluster|
      # kill the first / and replace any other occurence with a dot
      app_id = app_id.slice(1, app_id.length - 1)
      app_id = app_id.gsub('/', '.')

      cfgfile = "#{confd_path}/#{app_id}.instances"
      tmpfile = "#{cfgfile}.tmp"

      new_files << cfgfile

      flags = File::CREAT | File::TRUNC | File::WRONLY
      mode = 0644

      File.open(tmpfile, flags, mode) do |file|
        cluster.instances.each do |instance|
          file.write "#{instance.host}:#{instance.port}\n"
        end
      end

      # only write this file if it changes content (to preserve mtime)
      if !File.exist?(cfgfile) then
        logger.debug "confd: new #{cfgfile}"
        FileUtils.mv(tmpfile, cfgfile)
      elsif !FileUtils.identical?(tmpfile, cfgfile) then
        logger.debug "confd: refresh #{cfgfile}"
        FileUtils.mv(tmpfile, cfgfile)
      else
        FileUtils.rm(tmpfile)
      end
    end

    superfluous_files = old_files - new_files
    if !superfluous_files.empty? then
      logger.debug "Removing superfluous files: #{superfluous_files}"
      FileUtils.rm_f(superfluous_files)
    end
  end

  def collect_files
    Dir.entries(@confd_path).reject {|f| f == '.' || f == '..' }.
                             map{|f| "#{@confd_path}/#{f}"}
  end
end # }}}
class MarathonServiceDiscovery # {{{
  def initialize(marathon_host, marathon_port, groups, handlers, logger)
    @marathon_host = marathon_host
    @marathon_port = marathon_port
    @groups = groups
    @logger = logger
    @handlers = handlers

    events_url = "http://#{marathon_host}:#{marathon_port}/v2/events"
    logger.info "Listening on URL #{events_url}"
    @source = EventMachine::EventSource.new(events_url)
  end

  def logger
    @logger
  end

  def run
    reset_from_tasks(true)

    EM.run do
      @source.error {|message| sse_error(message)}
      @source.on 'status_update_event' do |json| status_update_event(json) end
      @source.on 'health_status_changed_event' do |json| health_status_changed_event(json) end
      @source.on 'deployment_success' do |json| deployment_success(json) end

      @source.start
    end
  end

  def sse_error(message)
    logger.error "SSE stream error. #{message}"
  end

  def status_update_event(json)
    logger.debug "on[status_update_event]:"
    obj = JSON.parse(json)

    slave_id = obj['slaveId']
    task_status = obj['taskStatus']
    message = obj['message']
    app_id = obj['appId']
    host = obj['host']
    port = obj['ports'][0]
    timestamp = obj['timestamp']

    if task_status == 'TASK_RUNNING' then
      logger.debug "[#{app_id}] new instance on #{host}:#{port}"
    else
      logger.debug "[#{app_id}] instance on #{host}:#{port} is #{task_status}"
    end

    reset_from_tasks
  end

  def health_status_changed_event(json)
    logger.debug "on[health_status_changed_event]:"
    reset_from_tasks
  end

  def deployment_success(json)
    logger.debug "on[deployment_success]:"
    reset_from_tasks
  end

private

  def reset_from_tasks(force = false)
    clusters = collect_clusters

    @handlers.each {|handler| handler.apply(clusters, force)}
  end

  def collect_clusters
    clusters = {}

    uri = "http://#{@marathon_host}:#{@marathon_port}/v2/tasks?embed=tasks.apps"
    response = Net::HTTP.get(URI(uri))
    obj = JSON.parse(response)

    tasks = obj['tasks']
    tasks.each do |task|
      name = task['id']
      host = task['host']
      port = task['ports'][0]
      app_id = task['appId'].gsub('/', '.')
      service_port = task['servicePorts'][0] # XXX only the first one as primary

      if should_include?(app_id) then
        cluster = clusters[app_id]
        if cluster  == nil then
          mode = 'tcp' # TODO: one of (tcp, http, ...)
          cluster = clusters[app_id] = AppCluster.new(app_id, service_port, mode)
          # TODO: add health check definitions
        end
        cluster.add_backend(name, host, port)
      end
    end

    clusters
  end

  def should_include?(app_id)
    true # TODO: filter by @groups
  end

  def dump_clusters(clusters)
    clusters.each do |app_id, cluster|
      puts "* #{cluster.app_id} #{cluster.service_port}"
      cluster.instances.each do |i|
        puts "  + #{i.host}:#{i.port}"
      end
    end
  end
end
# }}}
class Mmsd # {{{
  def self.run(argv)
    mmsd = Mmsd.new(argv)
    mmsd.main
  end

  OPT_DEFAULTS = {'marathon-host' => '',
                  'marathon-port' => '',
                  'groups' => '*',
                  'haproxy-bin' => '/usr/sbin/haproxy',
                  'haproxy-pidfile' => '/var/run/haproxy.pid',
                  'haproxy-cfg' => '/var/run/haproxy.cfg',
                  'haproxy-bind' => '0.0.0.0',
                  'haproxy-port' => '8081',
                  'upstream-confd' => '/var/run/mmsd/confd',
                  'log-level' => 'info'}

  def initialize(argv)
    @args = read_env(OPT_DEFAULTS)
    parse_args(argv, @args)
  end

  def read_env(defaults)
    opts = {}

    defaults.each do |name, default_value|
      env_name = name.gsub('-', '_').upcase
      env_value = ENV[env_name]

      opts[name] = env_value || default_value
    end

    opts
  end

  def parse_args(argv, opts)
    argv.each do |arg|
      name, value = arg.split('=')
      name.gsub!(/^--/, '')
      opts[name] = value
    end
  end

  def to_loglevel(value)
    puts "to_loglevel: #{value}"
    case value
    when 'debug'
      Logger::DEBUG
    when 'info'
      Logger::INFO
    when 'warn'
      Logger::WARN
    when 'error'
      Logger::ERROR
    else
      Logger::ERROR
    end
  end

  def main
    $stdout.sync = true

    logger = Logger.new(STDOUT)
    logger.level = to_loglevel(getopt('log-level'))

    handlers = []
    handlers << UpstreamConfDirHandler.new(getopt('upstream-confd'), logger)
    handlers << HaproxyBuilder.new(getopt('haproxy-bin'),
                                   getopt('haproxy-cfg'),
                                   getopt('haproxy-pidfile'),
                                   getopt('haproxy-bind'),
                                   getopt('haproxy-port').to_i,
                                   logger)

    sd = MarathonServiceDiscovery.new(getopt('marathon-host'),
                                      getopt('marathon-port').to_i,
                                      getopt('groups'),
                                      handlers,
                                      logger)
    sd.run
  end

  def getopt(name)
    puts "getopt[#{name}] = #{(@args[name] || '').inspect}"
    @args[name] || ''
  end
end
# }}}

Mmsd.run(ARGV)
